# This unit implements Tyler's M Estimator of 'shape' (Tyler, 1987)
# and the normalized regularized version of Zhang and Wiesel (2016)
#
#  MIT License
#  Copyright (c) 2020
#  Marco Congedo, CNRS, UGA, Grenoble-INP, Grenoble, France
#  https://sites.google.com/site/marcocongedo/
#
# ? CONTENT
#
# FUNCTIONS:
# tme   | Tyler M-Estimator fixed point algorithm (Tyler, 1987)
# nrtme | normalized regularized Tyler's M-Estimator (Zhang and Wiesel, 2016)
#
# REFERENCES
# David E. Tyler (1987)
# A Distribution-Free M-Estimator of Multivariate Scatter
# The Annals of Statistics, 15(1), 234-251.
# https://projecteuclid.org/download/pdf_1/euclid.aos/1176350263

# Teng Zhang, Ami Wiesel (2016)
# Automatic diagonal loading for Tyler's robust covariance estimator
# IEEE Statistical Signal Processing Workshop (SSP), 1-5.
# https://sciences.ucf.edu/math/tengz/wp-content/uploads/sites/45/2016/08/automatic-diagonal-loading-3.pdf

"""
    TylerMEstimator(; tol::Real = 1e-6, maxiter::Int = 200, verbose::Bool = false)

Tyler M-Estimator fixed point algorithm (Tyler, 1987)
`tol` is the stopping criterion
`maxiter` is the maximum number of iterations allowed
if `verbose`, information on convergence will be printed in the REPL.
"""
struct TylerMEstimator{TTol<:Real} <: CovarianceEstimator
    tol::TTol
    maxiter::Int
    verbose::Bool
end

function TylerMEstimator(; tol::Real = 1e-6, maxiter::Int = 200, verbose::Bool = false)
    TylerMEstimator(tol, maxiter, verbose)
end

function cov(tme::TylerMEstimator, X::AbstractMatrix{T}) where {T<:Union{Real,Complex}}
    tol = real(T)(tme.tol)
    maxiter = tme.maxiter
    verbose = tme.verbose
    n, t = size(X)
    R = Matrix{T}(I, n, n)
    Rnew = Matrix{T}(undef, n, n)
    iter, ðŸ˜‹ = 1, false

    verbose && println("Iterating M-estimator fixed-point algorithm...")
    while true
        C = cholesky(R)
        fill!(Rnew, zero(T))
        @inbounds for i = 1:t
            @views v = C.L \ X[:, i]
            Rnew += (X[:, i] .* X[:, i]') ./ (v â‹… v)
        end
        Rnew *= inv(tr(Rnew))
        conv = norm(Rnew - R) / norm(R)
        verbose && println("iteration: ", iter, "; convergence: ", conv)
        (overRun = iter == maxiter) && @warn(
            "M-estimator reached the max number of iterations before convergence:",
            iter,
        )
        (ðŸ˜‹ = conv <= tol) || overRun == true ? break : (iter += 1; R[:] = Rnew)
    end # while
    verbose && @info("Convergence has " * (ðŸ˜‹ ? "" : "not ") * "been attained.\n\n")
    return Rnew
end


## normalized regularized Tyler's M-Estimator (Zhang and Wiesel, 2016)
# `X` (the data) must be a wide matrix (for the sake of efficiency)
# if `reg` is `:RMT` (default) the random matrix theory shrinkage is used.
# 	Any other ymbol will use the Ledoit & Wolf shrinkage.
# `tol` is the stopping criterion
# `maxiter` is the maximum number of iterations allowed
# if `verbose`, information on convergence will be printed in the REPL.
function nrtme( X::AbstractMatrix{T};
                reg::Symbol = :RMT,
                tol::Real = real(T)(1e-6),
                maxiter::Int = 200,
                verbose::Bool = false) where {T<:Union{Real,Complex}}
    n, t = size(X)
    R = Matrix{T}(I, n, n)
    Rnew = zeros(T, n, n)
    x = Matrix{T}(undef, n, 1)
    v = Vector{T}(undef, n)
    iter, ðŸ˜‹, Î±, Î², ntâ»Â¹ = 1, false, 0.0, 0.0, n / t
    xÂ² = [xâ‹…x for x âˆˆ eachcol(X)]

    if reg == :RMT
        @inbounds for i=1:t
            x[:] = X[:, i]
            BLAS.gemm!('N', 'T', inv(xÂ²[i]), x, x, 1., Rnew) # | instead of Rnew += (X[:, i].*X[:, i]')./xÂ²[i]
        end
        Î¶ = n * tr((Rnew ./ t)^2) - ntâ»Â¹ - 1.
    else
        scm = (X * X') .* inv(n)
        Î¶ = (n * tr(scm^2) / (tr(scm))^2) - 1.
    end
    Î± = clamp(inv(t) * ((Î¶ + 1 + n) / (Î¶ + ntâ»Â¹)), 0., 1.)
    Î² = 1. - Î±
    Î±nâ»Â¹ = Î± / n
    g(x, Î²) = BLAS.gemm('N', 'T', Î², x, x)

    verbose && println("Iterating nrM-estimator fixed-point algorithm...")
    while true
        # compute tr(Râ»Â¹) = tr(Diagonal(Lâ»Â¹'*Lâ»Â¹))
        if n<400 BLAS.set_num_threads(1) end
        L = cholesky(R)
        Lâ»Â¹ = inv(L.L)
        trRâ»Â¹ = T(0)
        for j = 1:n, i = j:n @inbounds trRâ»Â¹ += abs2(Lâ»Â¹[i, j]) end
        if n<400 BLAS.set_num_threads(Sys.CPU_THREADS) end

        fill!(Rnew, zero(T))
        for i = 1:t
            x[:] = X[:, i]
            v[:] = L \ x
            c = Î±nâ»Â¹ * xÂ²[i]
            Rnew += (g(x, Î²) + c*I) ./ (Î²*(vâ‹…v) + c*trRâ»Â¹)
            #Rnew += (Î²*(x.*x')+(Î±nâ»Â¹*xÂ²[i])*I) ./ (Î²*(vâ‹…v)+Î±nâ»Â¹*trRâ»Â¹*xÂ²[i])
        end
        Rnew *= (inv(tr(Rnew)))
        conv = norm(Rnew - R) / norm(R)

        verbose && println("iteration: ", iter, "; convergence: ", conv)
        (overRun = iter == maxiter) && @warn(
            "nrM-estimator reached the max number of iterations before convergence:",
            iter,
        )
        (ðŸ˜‹ = conv <= tol) || overRun == true ? break : (iter += 1; R[:] = Rnew)
    end # while
    verbose && @info("Convergence has " * (ðŸ˜‹ ? "" : "not ") * "been attained.\n\n")
    return Rnew
end
